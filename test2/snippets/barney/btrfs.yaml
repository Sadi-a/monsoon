variant: flatcar
version: 1.0.0
systemd:
  units:
    - name: mkfs.service
      # There are two sensible approaches to persistent state:
      #
      #    1. use a storage system that provides strong recoverability; or,
      #
      #    2. say "no" to persistence; reboot into a clean (blank) state.
      #
      # ...and... then there's UNIX.  With UNIX, file data has no
      # recoverability guarantee (unless you call fsync(), which has
      # significant performance cost), yet users keep important data in
      # files that must survive reboot.  Amazingly, until relatively
      # recently, UNIX didn't even provide recoverability for metadata,
      # which meant that poorly timed power loss led to file system
      # corruption and manual repair.  Machines could spend hours when
      # rebooting running fsck to try to guess what state their file
      # system was in around the time of power loss.  At least with modern
      # UNIX file systems, the metadata is properly protected (journaled),
      # so the file system metadata always recovers into a consistent
      # state.  This does not solve the state-consistency problem; it
      # merely pushes it up to the user.  Barney could recover from
      # snapshot corruption; for example:
      #
      #  1. we could run "sync" periodically and then we could retain
      #     snapshots older than last_sync_time after a reboot; or,
      #
      #  2. we could write a content-hash of each snapshot to disk after
      #     persisting it, and then check the content hash of a snapshot
      #     the first time we consider using it after reboot.
      #
      #  3. we could throw away the entire snapshot cache on reboot.
      #
      # Here we go for the easiest: option 3.  (All of the same
      # considerations apply to the git-cache as well).

      # The way this is done here is by searching for the disks that
      # either have not been partitioned yet and thus can be used
      # for caching or disks that were previously used for caching
      # and thus use fstype `btrfs` as disks that are used

      enabled: true
      contents: |
        [Unit]
        Description=Format all non-persistent disks as one RAID0 btrfs volume
        Before=local-fs-pre.target mdadm.timer
        DefaultDependencies=no

        [Service]
        Type=oneshot
        ExecStart=:sh -c "mkfs.btrfs -f -L data${diskno} --data single --metadata single $(/opt/barney/list_unused_disks)"
        RemainAfterExit=true
        [Install]
        RequiredBy=local-fs.target
    - name: data${diskno}.mount
      enabled: true
      contents: |
        [Unit]
        Description= Mounting cached data
        After= mkfs.service
        DefaultDependencies=no
        [Mount]
        What=/dev/disk/by-label/data${diskno}
        Where=/data${diskno}
        Type=btrfs
        Options=nofail,user_subvol_rm_allowed
        TimeoutSec=120
        [Install]
        WantedBy=multi-user.target
    - name: b5cachedirs.service
      enabled: true
      contents: |
        [Unit]
        Description=Create b5 cache directory under /data${diskno}
        Requires=data${diskno}.mount
        After=data${diskno}.mount
        Before=local-fs.target
        DefaultDependencies=no
        [Service]
        Type=oneshot
        ExecStart=mkdir -p /data${diskno}/b5cache/barney-bsy
        ExecStart=chown 10000:10000 /data${diskno}/b5cache /data${diskno}/b5cache/barney-bsy
        ExecStart=chmod 755 /data${diskno}/b5cache /data${diskno}/b5cache/barney-bsy
        RemainAfterExit=true
        [Install]
        RequiredBy=local-fs.target
    - name: fstrim.timer
      # We need to run TRIM on SSDs periodically. This avoids slowdowns
      # caused by Write Amplification, which we are seeing after months
      # of usage without trimming. We used to fix this condition by simply
      # reformatting the btrfs array, which always TRIMs the disks by
      # default, but running fstrim achieves the same thing.
      enabled: true
      contents: |
        OnCalendar=Sat 01:00:00
        # We use a week as our random delay (7*24*(60**2)=604800) in order to
        # spread trims over that delay.
        # We use fixed random delays in order to make trims happen at
        # deterministic times for each host.
        RandomizedDelaySec=604800
        FixedRandomDelay=true
        # Make sure we only trim once per window across restarts.
        Persistent=true
storage:
  files:
    - path: /opt/barney/list_unused_disks
      mode: 0544
      contents:
        inline: |
          for device in /sys/block/*; do
            if readlink "$device" | grep -q virtual; then
              continue # Skip virtual devices
            fi
            echo -en "/dev$${device#/sys/block*}\t"
            udevadm info -a -p "$device" | awk -F '"' '/ATTR{size}/ { print $2 }'
          done | grep -v $(realpath ${used_disk}) | cut -f1
